<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Generalized Transformers from Applicative Functors | Blog</title>
<meta name="keywords" content="functional programming, machine learning">
<meta name="description" content="Transformers are a machine-learning model at the foundation of many state-of-the-art systems in modern AI, originally proposed in [arXiv:1706.03762]. In this post, we are going to build a generalization of Transformer models that can operate on (almost) arbitrary structures such as functions, graphs, probability distributions, not just matrices and vectors.
We will do this using the language of applicative functors, and indeed many of the constructions here have similar ideas to those presented in the original paper introducing applicative functors by McBride and Paterson, the only difference is that we interpret them in the context of machine learning, rather than in the context of functional programming with effects.">
<meta name="author" content="Tuomas Laakkonen">
<link rel="canonical" href="http://localhost:1313/posts/generalized-transformers/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8d858cbb412a86322299e9c90b4816f680e2d1667a9114b0d4c56c902f25eb09.css" integrity="sha256-jYWMu0EqhjIimenJC0gW9oDi0WZ6kRSw1MVskC8l6wk=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/generalized-transformers/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css"
  integrity="sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib"
  crossorigin="anonymous"
>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js"
  integrity="sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh"
  crossorigin="anonymous">
</script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js"
  integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh"
  crossorigin="anonymous"
  onload="renderMathInElement(document.body);">
</script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '$$', right: '$$', display: true},     
        {left: '$', right: '$', display: false},  
      ],
      throwOnError : false
    });
  });
</script>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script> 
</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Blog (Alt + H)">Blog</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Generalized Transformers from Applicative Functors
    </h1>
    <div class="post-meta"><span title='2025-02-24 19:52:00 -0500 EST'>February 24, 2025</span>&nbsp;·&nbsp;36 min&nbsp;·&nbsp;Tuomas Laakkonen&nbsp;·&nbsp;<a href='/tags/functional-programming' class='tag-in-list'>functional programming</a>&nbsp;·&nbsp;<a href='/tags/machine-learning' class='tag-in-list'>machine learning</a>

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#part-1-a-basic-model" aria-label="Part 1: A basic model">Part 1: A basic model</a></li>
                <li>
                    <a href="#part-2-fixing-the-problems" aria-label="Part 2: Fixing the problems">Part 2: Fixing the problems</a></li>
                <li>
                    <a href="#part-3-applicative-matrix-operations" aria-label="Part 3: Applicative matrix operations">Part 3: Applicative matrix operations</a></li>
                <li>
                    <a href="#part-4-diagrammatics" aria-label="Part 4: Diagrammatics">Part 4: Diagrammatics</a></li>
                <li>
                    <a href="#part-5-funcformer" aria-label="Part 5: Funcformer">Part 5: Funcformer</a></li>
                <li>
                    <a href="#part-6-a-generalized-transformer-zoo" aria-label="Part 6: A generalized Transformer zoo">Part 6: A generalized Transformer zoo</a><ul>
                        <ul>
                        
                <li>
                    <a href="#expression-trees-and-dags" aria-label="Expression trees and DAGs">Expression trees and DAGs</a></li>
                <li>
                    <a href="#probability-distributions" aria-label="Probability distributions">Probability distributions</a></li>
                <li>
                    <a href="#cross-modal-models" aria-label="Cross-modal models">Cross-modal models</a></li></ul>
                    </ul>
                </li>
                <li>
                    <a href="#part-7-conclusion" aria-label="Part 7: Conclusion">Part 7: Conclusion</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Transformers are a machine-learning model at the foundation of many state-of-the-art systems in modern AI, originally proposed in <a href="https://arxiv.org/abs/1706.03762">[arXiv:1706.03762]</a>. In this post, we are going to build a generalization of Transformer models that can operate on (almost) arbitrary structures such as functions, graphs, probability distributions, not just matrices and vectors.</p>
<p>We will do this using the language of <em>applicative functors</em>, and indeed many of the constructions here have similar ideas to those presented in the <a href="http://strictlypositive.org/IdiomLite.pdf">original paper</a> introducing applicative functors by McBride and Paterson, the only difference is that we interpret them in the context of machine learning, rather than in the context of functional programming with effects.</p>
<p>Although I&rsquo;m not aware of this particular construction appearing elsewhere in the wild, it is related to and inspired by various other models in the literature, in particular neural operators <a href="https://arxiv.org/abs/2108.08481">[arXiv:2108.08481]</a>, which define models very similar to the <em>Funcformer</em> model that we will present later.</p>
<p>This work is part of a series of similar ideas exploring machine learning through abstract diagrammatical means. If you think this is interesting, I would recommend reading other posts and papers in the same series, such as:</p>
<ul>
<li>On the anatomy of attention <a href="https://arxiv.org/abs/2407.02423">[arXiv:2407.02423]</a> (the &rsquo;tube&rsquo; notation in Part 4 is equivalent to the &lsquo;SIMD&rsquo; notation in that paper)</li>
<li>A pattern language for machine learning tasks <a href="https://arxiv.org/abs/2407.02424">[arXiv:2407.02424]</a></li>
</ul>
<p>These ideas were developed collaboratively in conversation with many colleagues, but in particular: Vincent Wang-Maścianica, Nikhil Khatri, Jono Liu, Ben Rodatz, Ian Fan, Neil Ortega, and Blake Wilson.</p>
<p>At its core, the Transformer is a method for <em>mapping sequences of vectors to sequences of vectors</em>. We will skip any conceptual explanation and go straight to the mathematics, since this has been explained at length elsewhere (for instance, <a href="https://www.3blue1brown.com/lessons/attention">by Grant Sanderson</a>). We have as input a sequences of $n$ vectors $x_i \in \mathbb{R}^d$, and the model outputs a sequence $y_i \in \mathbb{R}^d$ also of length $n$. Both of these are arranged as matrices $X, Y \in \mathbb{R}^{n \times d}$. The basic operation of a Transformer relies on interleaving two different operations: multi-layer perceptrons (MLPs) and self-attention. Given learnable matrices $Q, K \in \mathbb{R}^{d \times d_k}$, $V \in \mathbb{R}^{d \times d}$, $W_1 \in \mathbb{R}^{d \times d_{ff}}$, and $W_2 \in \mathbb{R}^{d_{ff} \times d}$, and vectors $b_1 \in \mathbb{R}^{d_{ff}}$ and $b_2 \in \mathbb{R}^{d}$, these operations can be expressed as follows</p>
$$
\begin{aligned}
    &\mathrm{MLP} : \mathbb{R}^{n \times d} \to \mathbb{R}^{n \times d} &~~~~ &\mathrm{SelfAtt : \mathbb{R}^{n \times d} \to \mathbb{R}^{n \times d}}\\
    &\mathrm{MLP}(X) = \sigma(XW_1 + 1_nb_1^T)W_2 + 1_nb_2^T & &\mathrm{SelfAtt(X) = \rho(XQ(XK)^T)XV}\\
\end{aligned}
$$<p>where $1_n \in \mathbb{R}^n$ is the all-ones vector, $\sigma : \mathbb{R} \to \mathbb{R}$ is an activation function applied element-wise that is usually taken as $\sigma(x) = \mathrm{ReLU}(x) = \max(x, 0)$, and $\rho : \mathbb{R}^n \to \mathbb{R}^n$ is a normalization function applied to each column that is usually taken as the scaled softmax:</p>
$$\rho(x)_i = \frac{e^{x_i}}{\sqrt{d_k}\sum_i e^{x_i}}$$<p>A (single-headed) Transformer can be built by iterating these functions (each with separate learnable weights) along with some other components like residuals and layer-norms that we will omit here for simplicity.</p>
<h2 id="part-1-a-basic-model">Part 1: A basic model<a hidden class="anchor" aria-hidden="true" href="#part-1-a-basic-model">#</a></h2>
<p>Suppose we wanted to implement a machine-learning model like the Transformer in a functional programming language - in this post we will use Haskell. We can start with a very naive type-level model, taking vectors as lists and matrices as lists of row-vectors. It is easy to build up the basic components like dot products, vector-matrix multiplication, and matrix-vector multiplication:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75715e">-- Dot product of two vectors</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">dot</span> <span style="color:#f92672">::</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#00a8c8">Float</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">dot</span> <span style="color:#111">a</span> <span style="color:#111">b</span> <span style="color:#f92672">=</span> <span style="color:#111">sum</span> <span style="color:#f92672">$</span> <span style="color:#111">zipWith</span> <span style="color:#111">(</span><span style="color:#f92672">*</span><span style="color:#111">)</span> <span style="color:#111">a</span> <span style="color:#111">b</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Multiply a matrix by a vector from the right</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMV</span> <span style="color:#f92672">::</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMV</span> <span style="color:#111">m</span> <span style="color:#111">v</span> <span style="color:#f92672">=</span> <span style="color:#111">map</span> <span style="color:#111">(`</span><span style="color:#111">dot</span><span style="color:#111">`</span> <span style="color:#111">v</span><span style="color:#111">)</span> <span style="color:#111">m</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Sum a list of vectors</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">vectorSum</span> <span style="color:#f92672">::</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">vectorSum</span> <span style="color:#f92672">=</span> <span style="color:#111">foldl</span> <span style="color:#111">(</span><span style="color:#111">zipWith</span> <span style="color:#111">(</span><span style="color:#f92672">+</span><span style="color:#111">))</span> <span style="color:#111">(</span><span style="color:#111">repeat</span> <span style="color:#ae81ff">0.0</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Multiply a matrix by a vector from the left</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulVM</span> <span style="color:#f92672">::</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulVM</span> <span style="color:#111">v</span> <span style="color:#111">m</span> <span style="color:#f92672">=</span> <span style="color:#111">vectorSum</span> <span style="color:#f92672">$</span> <span style="color:#111">zipWith</span> <span style="color:#111">(</span><span style="color:#111">map</span> <span style="color:#f92672">.</span> <span style="color:#111">(</span><span style="color:#f92672">*</span><span style="color:#111">))</span> <span style="color:#111">v</span> <span style="color:#111">m</span> 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Multiply a matrix by another matrix</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMM</span> <span style="color:#f92672">::</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMM</span> <span style="color:#111">a</span> <span style="color:#111">b</span> <span style="color:#f92672">=</span> <span style="color:#111">map</span> <span style="color:#111">(`</span><span style="color:#111">mulVM</span><span style="color:#111">`</span> <span style="color:#111">b</span><span style="color:#111">)</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Multiply a matrix by the transpose of another matrix</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMMT</span> <span style="color:#f92672">::</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMMT</span> <span style="color:#111">a</span> <span style="color:#111">b</span> <span style="color:#f92672">=</span> <span style="color:#111">map</span> <span style="color:#111">(</span><span style="color:#111">a</span> <span style="color:#111">`</span><span style="color:#111">mulMV</span><span style="color:#111">`)</span> <span style="color:#111">b</span>
</span></span></code></pre></div><p>And from here we can build the MLP and self-attention operations. In this case we build self-attention from a generic attention operation, where $XQ$, $XK$, and $XV$ are provided directly:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">scaleSoftmax</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Int</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">scaleSoftmax</span> <span style="color:#111">dk</span> <span style="color:#111">v</span> <span style="color:#f92672">=</span> <span style="color:#111">map</span> <span style="color:#111">(</span><span style="color:#f92672">/</span> <span style="color:#111">n</span><span style="color:#111">)</span> <span style="color:#111">e</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">where</span> <span style="color:#111">e</span> <span style="color:#f92672">=</span> <span style="color:#111">map</span> <span style="color:#111">exp</span> <span style="color:#111">v</span>
</span></span><span style="display:flex;"><span>          <span style="color:#111">n</span> <span style="color:#f92672">=</span> <span style="color:#111">sqrt</span> <span style="color:#111">(</span><span style="color:#111">fromIntegral</span> <span style="color:#111">dk</span><span style="color:#111">)</span> <span style="color:#f92672">*</span> <span style="color:#111">sum</span> <span style="color:#111">e</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- A generic attention function, before the inputs are specialized</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">attention</span> <span style="color:#f92672">::</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">attention</span> <span style="color:#111">queries</span> <span style="color:#111">keys</span> <span style="color:#111">values</span> <span style="color:#f92672">=</span> <span style="color:#111">attMatrix</span> <span style="color:#111">`</span><span style="color:#111">mulMM</span><span style="color:#111">`</span> <span style="color:#111">values</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">where</span> <span style="color:#111">dk</span> <span style="color:#f92672">=</span> <span style="color:#111">length</span> <span style="color:#f92672">$</span> <span style="color:#111">head</span> <span style="color:#111">queries</span>
</span></span><span style="display:flex;"><span>          <span style="color:#75715e">-- The &#39;attention matrix&#39;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#111">attMatrix</span> <span style="color:#f92672">=</span> <span style="color:#111">map</span> <span style="color:#111">(</span><span style="color:#111">scaleSoftmax</span> <span style="color:#111">dk</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">queries</span> <span style="color:#111">`</span><span style="color:#111">mulMMT</span><span style="color:#111">`</span> <span style="color:#111">keys</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">selfAttention</span> <span style="color:#f92672">::</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">selfAttention</span> <span style="color:#00a8c8">Q</span> <span style="color:#00a8c8">K</span> <span style="color:#00a8c8">V</span> <span style="color:#00a8c8">X</span> <span style="color:#f92672">=</span> <span style="color:#111">attention</span> <span style="color:#111">(</span><span style="color:#00a8c8">X</span> <span style="color:#111">`</span><span style="color:#111">mulMM</span><span style="color:#111">`</span> <span style="color:#00a8c8">Q</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#00a8c8">X</span> <span style="color:#111">`</span><span style="color:#111">mulMM</span><span style="color:#111">`</span> <span style="color:#00a8c8">Q</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#00a8c8">X</span> <span style="color:#111">`</span><span style="color:#111">mulMM</span><span style="color:#111">`</span> <span style="color:#00a8c8">V</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- Apply a linear function f(X) = XW^T + 1b^T to the input</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">linear</span> <span style="color:#f92672">::</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">linear</span> <span style="color:#111">weights</span> <span style="color:#111">bias</span> <span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">map</span> <span style="color:#111">(</span><span style="color:#111">zipWith</span> <span style="color:#111">(</span><span style="color:#f92672">+</span><span style="color:#111">)</span> <span style="color:#111">bias</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">input</span> <span style="color:#111">`</span><span style="color:#111">mulMMT</span><span style="color:#111">`</span> <span style="color:#111">weights</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mlp</span> <span style="color:#f92672">::</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mlp</span> <span style="color:#00a8c8">W1</span> <span style="color:#111">b1</span> <span style="color:#00a8c8">W2</span> <span style="color:#111">b2</span> <span style="color:#00a8c8">X</span> <span style="color:#f92672">=</span> <span style="color:#111">linear</span> <span style="color:#00a8c8">W2</span> <span style="color:#111">b2</span> <span style="color:#f92672">$</span> <span style="color:#111">map</span> <span style="color:#111">(</span><span style="color:#111">map</span> <span style="color:#111">relu</span><span style="color:#111">)</span> <span style="color:#f92672">$</span> <span style="color:#111">linear</span> <span style="color:#00a8c8">W1</span> <span style="color:#111">b1</span> <span style="color:#00a8c8">X</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">where</span> <span style="color:#111">relu</span> <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#111">max</span> <span style="color:#ae81ff">0.0</span> <span style="color:#111">x</span>
</span></span></code></pre></div><p>There are two major problems with this code:</p>
<ol>
<li>Since the dimensions of the problem are not encoded in the types, it would be easy to pass a malformed input to these functions. For example, accidentally transposing the weights of an MLP would neither be caught at compile-time nor result in a runtime error.</li>
<li>It would seem this code is too specific - all these operations ought to be possible over more generic structures than just <code>[[Float]]</code>, wouldn&rsquo;t it be better if the code could handle any appropriate structure?</li>
</ol>
<h2 id="part-2-fixing-the-problems">Part 2: Fixing the problems<a hidden class="anchor" aria-hidden="true" href="#part-2-fixing-the-problems">#</a></h2>
<p>We will solve both of these at the same time. As a first guess, since the list type is a monad, is it it possible to generalize this code to any monad? The components we would need are:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">map</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span><span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">b</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#111">a</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#111">b</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">zipWith</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span><span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">b</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">c</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#111">a</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#111">b</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#111">c</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">vectorSum</span> <span style="color:#f92672">::</span> <span style="color:#111">[[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">sum</span> <span style="color:#f92672">::</span> <span style="color:#111">[</span><span style="color:#00a8c8">Float</span><span style="color:#111">]</span> <span style="color:#f92672">-&gt;</span> <span style="color:#00a8c8">Float</span>
</span></span></code></pre></div><p>This initially looks promising, since we could substitute the first three with</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">fmap</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Functor</span> <span style="color:#111">f</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">(</span><span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">b</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">b</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">liftM2</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Monad</span> <span style="color:#111">m</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">(</span><span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">b</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">c</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">m</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">m</span> <span style="color:#111">b</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">m</span> <span style="color:#111">c</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">liftM2</span> <span style="color:#111">f</span> <span style="color:#111">xs</span> <span style="color:#111">ys</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">do</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">x</span> <span style="color:#f92672">&lt;-</span> <span style="color:#111">xs</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">y</span> <span style="color:#f92672">&lt;-</span> <span style="color:#111">ys</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">return</span> <span style="color:#f92672">$</span> <span style="color:#111">f</span> <span style="color:#111">x</span> <span style="color:#111">y</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">join</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Monad</span> <span style="color:#111">m</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">m</span> <span style="color:#111">(</span><span style="color:#111">m</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">m</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">join</span> <span style="color:#f92672">=</span> <span style="color:#111">(</span><span style="color:#f92672">&gt;&gt;=</span> <span style="color:#111">id</span><span style="color:#111">)</span>
</span></span></code></pre></div><p>and the type signatures would match! However, substituting the list monad into these functions gives the wrong answer - while <code>fmap</code> is correct, <code>liftM2</code> and <code>join</code> behave like cartesian products rather than like <code>zip</code>s:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">liftM2</span> <span style="color:#111">(,)</span> <span style="color:#111">[</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">]</span> <span style="color:#111">[</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">]</span> <span style="color:#f92672">=</span> <span style="color:#111">[(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">1</span><span style="color:#111">),</span> <span style="color:#111">(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">),</span> <span style="color:#111">(</span><span style="color:#ae81ff">2</span><span style="color:#111">,</span> <span style="color:#ae81ff">1</span><span style="color:#111">),</span> <span style="color:#111">(</span><span style="color:#ae81ff">2</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">)]</span> 
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">!=</span> <span style="color:#111">[(</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">1</span><span style="color:#111">),</span> <span style="color:#111">(</span><span style="color:#ae81ff">2</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">)]</span> 
</span></span><span style="display:flex;"><span>                         <span style="color:#f92672">=</span> <span style="color:#111">zip</span> <span style="color:#111">[</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">]</span> <span style="color:#111">[</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">]</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">join</span> <span style="color:#111">[[</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">],</span> <span style="color:#111">[</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">]]</span> <span style="color:#f92672">=</span> <span style="color:#111">[</span><span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">,</span> <span style="color:#ae81ff">1</span><span style="color:#111">,</span> <span style="color:#ae81ff">2</span><span style="color:#111">]</span>
</span></span></code></pre></div><p>Indeed, this is also related to our first problem. To solve that, let&rsquo;s assume that the dimension of each vector was encoded in its type as <code>Vector N a</code> where <code>N</code> is a type-level natural number. As before, we will take matrices to be vectors of vectors. In this setting, no function that has this cartesian-product behaviour could exist, because the length of the vector would not be preserved, so it would not type-check. It seems even that <code>Vector N</code> <em>cannot</em> be a monad in a non-trivial way, because any <code>join</code>-like function would have to &rsquo;throw away some information&rsquo; in general: since there are no non-trivial generic functions <code>a -&gt; a -&gt; a</code>, then given $N^2$ values of a generic type <code>a</code> that we must compress to only $N$ values, we have to discard almost all of them.</p>
<p>For the same reasons, such a generic version of <code>vectorSum</code> or <code>sum</code> that applies to any interior type <code>a</code> is too generic - we would end up throwing away information. The solution for this is to just abstract over these definitions. Let&rsquo;s define a class that encapsulates these operations:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">class</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#f92672">::</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">a</span>
</span></span></code></pre></div><p>So for instance we would have <code>Monad m =&gt; Counit m (m a)</code> given by <code>join</code>, and for comonads we could have <code>Comonad m =&gt; Counit m a</code> given by <code>extract</code>. In this way, we don&rsquo;t have to define <code>Counit</code> generically, but only for types <code>a</code> which have a meaningful and non-trivial <code>counit</code> operation.</p>
<p>To solve the problem with <code>liftM2</code>, we can be careful to define <code>Vector N</code> so that <code>fmap</code> behaves the same as <code>map</code> and <code>liftM2</code> does behave the same as <code>zipWith</code>. However, as we determined, <code>Vector N</code> shouldn&rsquo;t be a monad. But it <em>can</em> be an applicative functor! Indeed, <code>liftM2</code> is the monad specialization of <code>liftA2</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">liftA2</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">(</span><span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">b</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">c</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">b</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">c</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">liftA2</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#111">b</span> <span style="color:#f92672">=</span> <span style="color:#111">(</span><span style="color:#111">fmap</span> <span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">&lt;*&gt;</span> <span style="color:#111">b</span>
</span></span></code></pre></div><p>Applicative functors are a superset of monads that are defined by the <code>Applicative</code> class. It is usually defined by a pair of functions</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">pure</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">f</span> <span style="color:#f92672">&lt;*&gt;</span> <span style="color:#111">a</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">b</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">b</span>
</span></span></code></pre></div><p>where if we think of applicative functors as collections, <code>pure</code> can be interpreted as a &lsquo;unit&rsquo; mapping any value into a collection, and <code>&lt;*&gt;</code> can be interpreted as taking a collection of functions and a collection of arguments and returning a collection of results. However, there is a more concrete  definition in terms of <code>pair</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">pair</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">b</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#111">b</span><span style="color:#111">)</span>
</span></span></code></pre></div><p>which can be thought of as pairing up elements of collections. These definitions are equivalent, since we have:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">pair</span> <span style="color:#111">a</span> <span style="color:#111">b</span> <span style="color:#f92672">=</span> <span style="color:#111">(</span><span style="color:#111">fmap</span> <span style="color:#111">(,)</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">&lt;*&gt;</span> <span style="color:#111">b</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">f</span> <span style="color:#f92672">&lt;*&gt;</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#111">fmap</span> <span style="color:#111">(</span><span style="color:#111">uncurry</span> <span style="color:#111">(</span><span style="color:#f92672">$</span><span style="color:#111">))</span> <span style="color:#f92672">$</span> <span style="color:#111">pair</span> <span style="color:#111">f</span> <span style="color:#111">a</span> 
</span></span></code></pre></div><p>We will work in terms of <code>pair</code>, since this is closer to the category-theoretic definition of an applicative functor as a &lsquo;monoidal functor with tensorial strength&rsquo;.</p>
<p>With this in mind, we can define (ignoring some Haskell specifics regarding type-level naturals)</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">data</span> <span style="color:#00a8c8">Vector</span> <span style="color:#111">(</span><span style="color:#00a8c8">N</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Natural</span><span style="color:#111">)</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Vector</span> <span style="color:#111">[</span><span style="color:#111">a</span><span style="color:#111">]</span> 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Functor</span> <span style="color:#111">(</span><span style="color:#00a8c8">Vector</span> <span style="color:#00a8c8">N</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">fmap</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#00a8c8">Vector</span> <span style="color:#111">xs</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Vector</span> <span style="color:#f92672">$</span> <span style="color:#111">map</span> <span style="color:#111">f</span> <span style="color:#111">xs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">(</span><span style="color:#00a8c8">Vector</span> <span style="color:#00a8c8">N</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pure</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Vector</span> <span style="color:#f92672">$</span> <span style="color:#111">take</span> <span style="color:#00a8c8">N</span> <span style="color:#f92672">$</span> <span style="color:#111">repeat</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pair</span> <span style="color:#111">(</span><span style="color:#00a8c8">Vector</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#00a8c8">Vector</span> <span style="color:#111">b</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Vector</span> <span style="color:#f92672">$</span> <span style="color:#111">zip</span> <span style="color:#111">a</span> <span style="color:#111">b</span>
</span></span></code></pre></div><p>and we can see that now <code>pair</code> matches exactly with <code>zip</code>, as we wanted! See page 4 of <a href="http://strictlypositive.org/IdiomLite.pdf">McBride and Paterson</a> for a similar construction.</p>
<h2 id="part-3-applicative-matrix-operations">Part 3: Applicative matrix operations<a hidden class="anchor" aria-hidden="true" href="#part-3-applicative-matrix-operations">#</a></h2>
<p>To recreate our original code in these new terms, we are still missing a few elements specific to <code>Float</code>s that we don&rsquo;t have in the generic picture. We will ignore the scaled-softmax and ReLU operations for now as they can in principle be replaced with any normalization and activation functions, and come back to them later. However, we still need a definitions of multiplication and addition. We will just abstract over these as a typeclass:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">class</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">zero</span> <span style="color:#f92672">::</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">(</span><span style="color:#f92672">~+~</span><span style="color:#111">)</span> <span style="color:#f92672">::</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">(</span><span style="color:#f92672">~*~</span><span style="color:#111">)</span> <span style="color:#f92672">::</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">a</span>
</span></span></code></pre></div><p>We can then recover our definitions of <code>sum</code> and <code>vectorSum</code> in terms of <code>Vector N</code> by constructing the appropriate <code>Counit</code> instances:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span> <span style="color:#f92672">=&gt;</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Vector</span> <span style="color:#00a8c8">N</span><span style="color:#111">)</span> <span style="color:#111">a</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Vector</span> <span style="color:#111">xs</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">foldl</span> <span style="color:#111">(</span><span style="color:#f92672">~+~</span><span style="color:#111">)</span> <span style="color:#111">zero</span> <span style="color:#111">xs</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#111">(</span><span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Vector</span> <span style="color:#00a8c8">N</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Vector</span> <span style="color:#111">xs</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">foldl</span> <span style="color:#111">((</span><span style="color:#f92672">.</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">fmap</span> <span style="color:#f92672">$</span> <span style="color:#111">uncurry</span> <span style="color:#111">(</span><span style="color:#f92672">~+~</span><span style="color:#111">))</span> <span style="color:#f92672">.</span> <span style="color:#111">pair</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">pure</span> <span style="color:#111">zero</span><span style="color:#111">)</span> <span style="color:#111">xs</span>
</span></span></code></pre></div><p>With these definitions, we can build a fully generic version of our code that also encode dimensionality information in the type-signatures. We need only operations from the typeclasses we&rsquo;ve defined, and substituting in <code>Vector</code> as our functor will yield something equivalent to our original code, and hence the original Transformer!</p>
<p>The matrix operations can be given as:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">dot</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span><span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">,</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">dot</span> <span style="color:#111">a</span> <span style="color:#111">b</span> <span style="color:#f92672">=</span> <span style="color:#111">counit</span> <span style="color:#f92672">$</span> <span style="color:#111">uncurry</span> <span style="color:#111">(</span><span style="color:#f92672">~*~</span><span style="color:#111">)</span> <span style="color:#f92672">&lt;$&gt;</span> <span style="color:#111">pair</span> <span style="color:#111">a</span> <span style="color:#111">b</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMV</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span><span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">g</span><span style="color:#111">,</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">g</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMV</span> <span style="color:#111">m</span> <span style="color:#111">v</span> <span style="color:#f92672">=</span> <span style="color:#111">uncurry</span> <span style="color:#111">dot</span> <span style="color:#f92672">&lt;$&gt;</span> <span style="color:#111">pair</span> <span style="color:#111">m</span> <span style="color:#111">(</span><span style="color:#111">pure</span> <span style="color:#111">v</span><span style="color:#111">)</span> 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulVM</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span><span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">g</span><span style="color:#111">,</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">))</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">g</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulVM</span> <span style="color:#111">v</span> <span style="color:#111">m</span> <span style="color:#f92672">=</span> <span style="color:#111">counit</span> <span style="color:#f92672">$</span> <span style="color:#111">fmap</span> <span style="color:#111">(</span><span style="color:#111">uncurry</span> <span style="color:#111">(</span><span style="color:#f92672">~*~</span><span style="color:#111">))</span> <span style="color:#f92672">.</span> <span style="color:#111">uncurry</span> <span style="color:#111">pair</span> <span style="color:#f92672">&lt;$&gt;</span> <span style="color:#111">pair</span> <span style="color:#111">(</span><span style="color:#111">pure</span> <span style="color:#f92672">&lt;$&gt;</span> <span style="color:#111">v</span><span style="color:#111">)</span> <span style="color:#111">m</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMMT</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Functor</span> <span style="color:#111">h</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">g</span><span style="color:#111">,</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">g</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">h</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">h</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMMT</span> <span style="color:#f92672">=</span> <span style="color:#111">fmap</span> <span style="color:#f92672">.</span> <span style="color:#111">mulMV</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMM</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Applicative</span> <span style="color:#111">h</span><span style="color:#111">,</span> <span style="color:#00a8c8">Functor</span> <span style="color:#111">f</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">g</span><span style="color:#111">,</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">g</span> <span style="color:#111">(</span><span style="color:#111">h</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">g</span> <span style="color:#111">(</span><span style="color:#111">h</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">h</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">mulMM</span> <span style="color:#f92672">=</span> <span style="color:#111">flip</span> <span style="color:#f92672">$</span> <span style="color:#111">fmap</span> <span style="color:#f92672">.</span> <span style="color:#111">flip</span> <span style="color:#111">mulVM</span>
</span></span></code></pre></div><p>So we see that instead of defining a matrix as <code>[[Float]]</code> and a vector as <code>[Float]</code>, these have become <code>f (g a)</code> and <code>f a</code> respectively for arbitrary type constructors <code>f</code> and <code>g</code> and arbitrary &lsquo;scalar&rsquo; types <code>a</code>. If <code>f</code> and <code>g</code> are different instances of <code>Vector N</code> for example, then this will prevent many bugs of the type we identified earlier with stronger compile-time checks.</p>
<p>By abstracting over the scaled-softmax and ReLU functions as arbitrary functions that can be passed in, we can define the generic attention and linear function operations as before:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">attention</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">g</span><span style="color:#111">,</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">attention</span> <span style="color:#111">softmax</span> <span style="color:#111">queries</span> <span style="color:#111">keys</span> <span style="color:#111">values</span> <span style="color:#f92672">=</span> <span style="color:#111">attMatrix</span> <span style="color:#111">`</span><span style="color:#111">mulMM</span><span style="color:#111">`</span> <span style="color:#111">values</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">where</span> <span style="color:#111">attMatrix</span> <span style="color:#f92672">=</span> <span style="color:#111">fmap</span> <span style="color:#111">softmax</span> <span style="color:#111">(</span><span style="color:#111">queries</span> <span style="color:#111">`</span><span style="color:#111">mulMMT</span><span style="color:#111">`</span> <span style="color:#111">keys</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">linear</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Applicative</span> <span style="color:#111">g1</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">g2</span><span style="color:#111">,</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">g1</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">g2</span> <span style="color:#111">(</span><span style="color:#111">g1</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">g2</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">g1</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">g2</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">linear</span> <span style="color:#111">weights</span> <span style="color:#111">bias</span> <span style="color:#111">input</span> <span style="color:#f92672">=</span> <span style="color:#111">fmap</span> <span style="color:#111">(</span><span style="color:#111">uncurry</span> <span style="color:#111">(</span><span style="color:#f92672">~+~</span><span style="color:#111">))</span> <span style="color:#f92672">$</span> <span style="color:#111">pair</span> <span style="color:#111">bias</span> <span style="color:#f92672">$</span> <span style="color:#111">mulMV</span> <span style="color:#111">weights</span> <span style="color:#111">input</span>
</span></span></code></pre></div><p>And we can put it all together to define self-attention and MLP operations. We can make it a bit nicer than before by packaging all the matrices together as data-structures:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">data</span> <span style="color:#00a8c8">SelfAttention</span> <span style="color:#111">s</span> <span style="color:#111">d</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">SelfAttention</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">-- This abstracts scaled-softmax</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">softmax</span> <span style="color:#f92672">::</span> <span style="color:#111">s</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">s</span> <span style="color:#111">a</span><span style="color:#111">,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">queryMat</span> <span style="color:#f92672">::</span> <span style="color:#111">d</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">),</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">keyMat</span> <span style="color:#f92672">::</span> <span style="color:#111">d</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">),</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">valueMat</span> <span style="color:#f92672">::</span> <span style="color:#111">d</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">runSelfAttention</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">s</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">d</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">s</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#00a8c8">SelfAttention</span> <span style="color:#111">s</span> <span style="color:#111">d</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">s</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">s</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">runSelfAttention</span> <span style="color:#00a8c8">SelfAttention</span> <span style="color:#111">{</span> <span style="color:#111">softmax</span><span style="color:#111">,</span> <span style="color:#111">queryMat</span><span style="color:#111">,</span> <span style="color:#111">keyMat</span><span style="color:#111">,</span> <span style="color:#111">valueMat</span> <span style="color:#111">}</span> <span style="color:#111">input</span> <span style="color:#f92672">=</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#111">attention</span> <span style="color:#111">softmax</span> <span style="color:#111">queries</span> <span style="color:#111">keys</span> <span style="color:#111">values</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">where</span> <span style="color:#111">queries</span> <span style="color:#f92672">=</span> <span style="color:#111">mulMMT</span> <span style="color:#111">queryMat</span> <span style="color:#111">input</span>
</span></span><span style="display:flex;"><span>          <span style="color:#111">keys</span> <span style="color:#f92672">=</span> <span style="color:#111">mulMMT</span> <span style="color:#111">keyMat</span> <span style="color:#111">input</span>
</span></span><span style="display:flex;"><span>          <span style="color:#111">values</span> <span style="color:#f92672">=</span> <span style="color:#111">mulMMT</span> <span style="color:#111">valueMat</span> <span style="color:#111">input</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">data</span> <span style="color:#00a8c8">MLP</span> <span style="color:#111">din</span> <span style="color:#111">dff</span> <span style="color:#111">dout</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">MLP</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">-- This abstracts ReLU</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">activation</span> <span style="color:#f92672">::</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">a</span><span style="color:#111">,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">weights1</span> <span style="color:#f92672">::</span> <span style="color:#111">dff</span> <span style="color:#111">(</span><span style="color:#111">din</span> <span style="color:#111">a</span><span style="color:#111">),</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">bias1</span> <span style="color:#f92672">::</span> <span style="color:#111">dff</span> <span style="color:#111">a</span><span style="color:#111">,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">weights2</span> <span style="color:#f92672">::</span> <span style="color:#111">dout</span> <span style="color:#111">(</span><span style="color:#111">dff</span> <span style="color:#111">a</span><span style="color:#111">),</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">bias2</span> <span style="color:#f92672">::</span> <span style="color:#111">dout</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#111">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">runMLP</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">dff</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">dout</span><span style="color:#111">,</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Counit</span> <span style="color:#111">dff</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">din</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">din</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#00a8c8">MLP</span> <span style="color:#111">din</span> <span style="color:#111">dff</span> <span style="color:#111">dout</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">din</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">dout</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">runMLP</span> <span style="color:#00a8c8">MLP</span> <span style="color:#111">{</span> <span style="color:#111">weights1</span><span style="color:#111">,</span> <span style="color:#111">bias1</span><span style="color:#111">,</span> <span style="color:#111">weights2</span><span style="color:#111">,</span> <span style="color:#111">bias2</span><span style="color:#111">,</span> <span style="color:#111">activation</span> <span style="color:#111">}</span> <span style="color:#f92672">=</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#111">linear</span> <span style="color:#111">weights2</span> <span style="color:#111">bias2</span> <span style="color:#f92672">.</span> <span style="color:#111">fmap</span> <span style="color:#111">activation</span> <span style="color:#f92672">.</span> <span style="color:#111">linear</span> <span style="color:#111">weights1</span> <span style="color:#111">bias1</span>
</span></span></code></pre></div><p>Finally, we can combine these blocks to make a whole Transformer. We are ignoring the layer-norms, and using only a single attention head, but otherwise this is identical to the original proposal from Vaswani et al:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75715e">-- One transformer layer is a self-attention block and an MLP block with residuals</span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">data</span> <span style="color:#00a8c8">TransformerLayer</span> <span style="color:#111">s</span> <span style="color:#111">d</span> <span style="color:#111">dff</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">TransformerLayer</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">mlp</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">MLP</span> <span style="color:#111">d</span> <span style="color:#111">dff</span> <span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">,</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">satt</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">SelfAttention</span> <span style="color:#111">s</span> <span style="color:#111">d</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#111">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">runTransformerLayer</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Ring</span> <span style="color:#111">b</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">dff</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">d</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">s</span><span style="color:#111">,</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Counit</span> <span style="color:#111">dff</span> <span style="color:#111">b</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">d</span> <span style="color:#111">b</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">s</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">b</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#00a8c8">TransformerLayer</span> <span style="color:#111">s</span> <span style="color:#111">d</span> <span style="color:#111">dff</span> <span style="color:#111">b</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">s</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">b</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">s</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">b</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">runTransformerLayer</span> <span style="color:#00a8c8">TransformerLayer</span> <span style="color:#111">{</span> <span style="color:#111">mlp</span><span style="color:#111">,</span> <span style="color:#111">satt</span> <span style="color:#111">}</span> <span style="color:#f92672">=</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#111">residual</span> <span style="color:#111">(</span><span style="color:#111">runMLP</span> <span style="color:#111">mlp</span> <span style="color:#f92672">&lt;$&gt;</span><span style="color:#111">)</span> <span style="color:#f92672">.</span> <span style="color:#111">residual</span> <span style="color:#111">(</span><span style="color:#111">runSelfAttention</span> <span style="color:#111">satt</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">where</span> <span style="color:#111">add</span> <span style="color:#111">x</span> <span style="color:#111">y</span> <span style="color:#f92672">=</span> <span style="color:#111">fmap</span> <span style="color:#111">(</span><span style="color:#111">uncurry</span> <span style="color:#111">(</span><span style="color:#f92672">~+~</span><span style="color:#111">))</span> <span style="color:#f92672">.</span> <span style="color:#111">uncurry</span> <span style="color:#111">pair</span> <span style="color:#f92672">&lt;$&gt;</span> <span style="color:#111">pair</span> <span style="color:#111">x</span> <span style="color:#111">y</span>
</span></span><span style="display:flex;"><span>          <span style="color:#111">residual</span> <span style="color:#111">f</span> <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#111">add</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#111">x</span> 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- A transformer is a linear embedding matrix, followed by a </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- stack of transformer layers composed sequentially, </span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">-- followed by a linear unembedding matrix</span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">data</span> <span style="color:#00a8c8">Transformer</span> <span style="color:#111">s</span> <span style="color:#111">f</span> <span style="color:#111">d</span> <span style="color:#111">dff</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Transformer</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">layers</span> <span style="color:#f92672">::</span> <span style="color:#111">[</span><span style="color:#00a8c8">TransformerLayer</span> <span style="color:#111">s</span> <span style="color:#111">d</span> <span style="color:#111">dff</span> <span style="color:#111">a</span><span style="color:#111">],</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">embed</span> <span style="color:#f92672">::</span> <span style="color:#111">d</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">),</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">unembed</span> <span style="color:#f92672">::</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">runTransformer</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">d</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">dff</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">s</span><span style="color:#111">,</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Counit</span> <span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">dff</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">s</span> <span style="color:#111">(</span><span style="color:#111">d</span> <span style="color:#111">a</span><span style="color:#111">),</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">f</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#00a8c8">Transformer</span> <span style="color:#111">s</span> <span style="color:#111">f</span> <span style="color:#111">d</span> <span style="color:#111">dff</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">s</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">s</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">runTransformer</span> <span style="color:#00a8c8">Transformer</span> <span style="color:#111">{</span> <span style="color:#111">layers</span><span style="color:#111">,</span> <span style="color:#111">embed</span><span style="color:#111">,</span> <span style="color:#111">unembed</span> <span style="color:#111">}</span> <span style="color:#f92672">=</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#111">mulMMT</span> <span style="color:#111">unembed</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span> <span style="color:#111">flip</span> <span style="color:#111">(</span><span style="color:#111">foldl</span> <span style="color:#111">(</span><span style="color:#111">flip</span> <span style="color:#111">runTransformerLayer</span><span style="color:#111">))</span> <span style="color:#111">layers</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">.</span> <span style="color:#111">mulMMT</span> <span style="color:#111">embed</span>
</span></span></code></pre></div><h2 id="part-4-diagrammatics">Part 4: Diagrammatics<a hidden class="anchor" aria-hidden="true" href="#part-4-diagrammatics">#</a></h2>
<p><em>(Many thanks to Vincent Wang-Maścianica for his help with this part)</em></p>
<p>All this uncurrying we needed to do to write the code above using <code>pair</code> is pretty miserable. That&rsquo;s because we are trying to do fundamentally 2D things in 1D and it sucks. Luckily there is a formal diagram system for this.</p>
<p>We build on the tube-notation for monoidal monads introduced by Joe Moeller in his <a href="https://joe-moeller.com/2020/07/09/tube-diagrams-for-monoidal-monads/">blogpost</a>, which is an evident extension of <a href="https://www.irif.fr/~mellies/papers/Mellies06csl.pdf">functor box notation</a>, by stretching out functor-boxes as &ldquo;windows&rdquo; along the length of wires to become &ldquo;tubes&rdquo;. So if we have an underlying symmetric monoidal category $(\mathcal{C},\otimes,I)$ along with a symmetric monoidal endofunctor $\mathbf{T}: \mathcal{C} \rightarrow \mathcal{C}$, we would depict the object $\mathbf{T}X$ of $\mathcal{C}$ as the wire $X$ wrapped by a $\mathbf{T}$-tube:</p>
<p><img alt="The object $\\mathbf{T}X$ depicted as the wire $X$ wrapped by a $\\mathbf{T}$-tube." loading="lazy" src="/posts/generalized-transformers/images/basictube.svg#center"></p>
<p>As is sort-of <a href="https://link.springer.com/chapter/10.1007/978-3-642-31113-0_15">known</a>, applicative functors are equivalently lax-monoidal functors with a tensorial strength. In tube-notation, the laxator natural transformation $\tau_{-,=} : \mathbf{T}(-) \otimes \mathbf{T}(=) \rightarrow \mathbf{T}(- \ \otimes =)$ are depicted as pants that merge two parallel tubes:</p>
<p><img alt="The monoidal laxator" loading="lazy" src="/posts/generalized-transformers/images/monoidalstrength.svg#center"></p>
<p>This is exactly the <code>pair</code> operation we have in the code above. The visual tube metaphor captures the naturality conditions we want string-diagrammatically, as deformation of string diagrams freely within the confines of tubes. For example, this pretty little monster is the naturality condition that allows the laxator to cohere with a simplified form of interchange, given two morphisms $f: A \rightarrow X$ and $g: B \rightarrow Y$:</p>
<p><img alt="Get a load of this guy" loading="lazy" src="/posts/generalized-transformers/images/laxcoherence.svg#center"></p>
<p>But all we&rsquo;re really asking for here in string-diagrammatic terms is that you can slide morphisms around in pants that merge tubes.</p>
<p><img alt="Much simpler" loading="lazy" src="/posts/generalized-transformers/images/slideinpants.svg#center"></p>
<p>The rest of the lax monoidal structure goes as one would expect. For example, we want the monoidal laxator to be appropriately associative (we won&rsquo;t label wires with types anymore, they can be object in the category.)</p>
<p><img alt="Laxator associativity" loading="lazy" src="/posts/generalized-transformers/images/strengthassoc.svg#center"></p>
<p>There&rsquo;s also another laxator $\nu: I \rightarrow \mathbf{T}I$ for the monoidal unit (depicted here with a dashed wire)</p>
<p><img alt="Unit laxator" loading="lazy" src="/posts/generalized-transformers/images/nu.svg#center"></p>
<p>And these laxators should behave as we expect, namely they should be appropriately unital. Below we get the middle equalities (depicting the left and right unitor isomorphisms of $\mathcal{C}$) for free, as we can assume that we&rsquo;re working with a strict symmetric monoidal category.</p>
<p><img alt="Left and right unitors" loading="lazy" src="/posts/generalized-transformers/images/unitors.svg#center"></p>
<p>And of course, we would like the laxators to cohere sensibly with braidings.</p>
<p><img alt="Laxator-braid coherence" loading="lazy" src="/posts/generalized-transformers/images/twistpants.svg#center"></p>
<p>Now the tensorial-strength, which is a natural transformation $\beta: - \otimes \mathbf{T}(=) \rightarrow \mathbf{T}(- \ \otimes =)$. In tube-notation, this corresponds to taking a wire and shoving it inside an adjacent tube.</p>
<p><img alt="Tensorial strength" loading="lazy" src="/posts/generalized-transformers/images/tensorstrength.svg#center"></p>
<p>There are a couple of coherence conditions we expect, namely that it doesn&rsquo;t matter whether we shove wires in one-by-one or all at once, that shoving-in the monoidal unit does nothing, and that shoving-in can be done from either side in a way that coheres with the braiding.</p>
<p><img alt="Strength associativity" loading="lazy" src="/posts/generalized-transformers/images/betaassoc.svg#center"></p>
<p><img alt="Strength unitality" loading="lazy" src="/posts/generalized-transformers/images/betaunitality.svg#center"></p>
<p><img alt="Strength-braid coherence" loading="lazy" src="/posts/generalized-transformers/images/betatwist.svg#center"></p>
<p>And we&rsquo;re done with the tricky bit. In terms of the code above, this is</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">beta</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">b</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#111">b</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">beta</span> <span style="color:#111">a</span> <span style="color:#111">b</span> <span style="color:#f92672">=</span> <span style="color:#111">pair</span> <span style="color:#111">(</span><span style="color:#111">pure</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#111">b</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">nu</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">()</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">()</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">nu</span> <span style="color:#111">()</span> <span style="color:#f92672">=</span> <span style="color:#111">pure</span> <span style="color:#111">()</span>
</span></span></code></pre></div><p>which along with $\tau$ (equivalently <code>pair</code>) and the right unitor $\rho$ from above is also enough to define <code>pure</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">rho</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#111">()</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">rho</span> <span style="color:#f92672">=</span> <span style="color:#111">fmap</span> <span style="color:#111">fst</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">pure</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">pure</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#111">rho</span> <span style="color:#f92672">$</span> <span style="color:#111">beta</span> <span style="color:#111">a</span> <span style="color:#f92672">$</span> <span style="color:#111">nu</span> <span style="color:#111">()</span>
</span></span></code></pre></div><p>completing the equivalence between the diagrams and the code.</p>
<p>The other ingredients we need are garden-varietal diagrammatic gadgets. We will need a copy-gadget, which we can have in any Cartesian (or Markov) category. Copy comonoids are traditionally depicted as dots that gather the various copied branches. Since we will be copying tubes, which will make dots too big, we will use a fork-notation for copying instead.</p>
<p><img alt="Copy map" loading="lazy" src="/posts/generalized-transformers/images/copy.svg#center"></p>
<p>We will need learnable parameters, such as weights and biases. These are just elements of a given object (for instance, $\mathbf{TT}X$ or $\mathbf{T}X$) and to be depicted as triangles, though to indicate that it is a learner with some parameter space, for historical reasons <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> we will colour them red.</p>
<p><img alt="A learned parameter" loading="lazy" src="/posts/generalized-transformers/images/learner.svg#center"></p>
<p>We will need an algebra $\alpha_X \mathbf{T}X \rightarrow X$ (this is <code>Counit</code>) which extracts wires from tubes. We&rsquo;ll depict these as triangles that cap off tubes.</p>
<p><img alt="An algebra " loading="lazy" src="/posts/generalized-transformers/images/algebra_colour.svg#center"></p>
<p>We will need some magma $X \otimes X \rightarrow X$ (this is <code>~*~</code> from <code>Ring</code>). In practice, the multiplication of any off-the-shelf monoid will do.</p>
<p><img alt="A monoid multiplication" loading="lazy" src="/posts/generalized-transformers/images/monoid_colour.svg#center"></p>
<p>Optionally, we may have a &ldquo;normalisation&rdquo; $\sigma: \mathbf{TT}X \rightarrow \mathbf{TT}X$ (which generalizes <code>softmax</code>).</p>
<p><img alt="A normalisation" loading="lazy" src="/posts/generalized-transformers/images/normalise.svg#center"></p>
<p>Now we can assemble these ingredients. The pants, magma, and the algebra allow us to define an abstract inner product of type $\mathbf{T}X \otimes \mathbf{T}X \rightarrow X$.</p>
<p><img alt="Inner product" loading="lazy" src="/posts/generalized-transformers/images/innerproduct.svg#center"></p>
<p>We can also define an abstract outer product of type $\mathbf{T}X \otimes \mathbf{T}X \rightarrow \mathbf{T}\mathbf{T}X$, using the magma and two instances of the tensorial strength of the applicative.</p>
<p><img alt="Outer product" loading="lazy" src="/posts/generalized-transformers/images/outerproduct.svg#center"></p>
<p>Now we&rsquo;re ready for the abstract attention mechanism. The idea is to use the outer product gadget to create a doubly-nested tube, and then to use the inner product gadget along with the pants and shoving of the applicative to bring that back down to a singly-nested tube, while liberally sprinkling in learners. Since the outer product requires two $\mathbf{T}X$ inputs, and we require at least one extra copy of $\mathbf{T}X$ apart from those to use the inner product, it makes sense to start with three copies of the initial input $\mathbf{T}X$, and a little thought will yield this:</p>
<p><img alt="An abstract attention mechanism" loading="lazy" src="/posts/generalized-transformers/images/attn3.svg#center"></p>
<p>For the sake of convention, we put learnable linear transformations on the three inputs and call them &ldquo;queries&rdquo;, &ldquo;keys&rdquo;, and &ldquo;values&rdquo;. This is exactly the same as <code>runSelfAttention</code>. If we pick $X$ to be $\mathbb{R}$, our applicative functor to be the $k$-tupling endofunctor $X \mapsto X^k$, where $k$ is some positive integer &ldquo;context-length&rdquo; for the outer tubes and a &ldquo;model dimension&rdquo; for the inner tubes, and if we choose our algebra to be summation, our monoid to be multiplication, and our normalisation to be softmax, then we have precisely a classic attention mechanism as in the matrix-based <code>selfAttention</code> above. The $\mathbf{TT}X$ wire in this case is the abstract analog of the <em>attention matrix</em>; the synthetic inner and outer products we define here are special cases of tensor contraction, where each index of a tensor corresponds to a layer of tubing.</p>
<h2 id="part-5-funcformer">Part 5: Funcformer<a hidden class="anchor" aria-hidden="true" href="#part-5-funcformer">#</a></h2>
<p>At this point, we are done in theory! We have a fully generalized construction of a Transformer model. However, what does this buy us in practice? Can we construct anything meaningfully different than the standard model? Indeed there is, and we shall look at one such construction now, which we call <em>Funcformer</em>. We start with this not necessarily because it is the most useful generalization we can make, but because it is the easiest to implement.</p>
<p>One potential generalization of the <code>Vector N</code> type comes from viewing any vector $v \in X^{n}$ over some type $X$ as a function from indices to components of the vector - i.e $v : \{1, 2, \dots, n\} \to X$ given by $v(i) = v_i$. There is no fundamental reason why this index set ought to be finite, or even discrete. To that end, let&rsquo;s define a &lsquo;continuous vector&rsquo; <code>CVector</code> which has &lsquo;components&rsquo; parameterized by a real number. We can define this in code as</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">newtype</span> <span style="color:#00a8c8">CVector</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">CVector</span> <span style="color:#111">{</span> <span style="color:#111">(</span><span style="color:#f92672">~!!~</span><span style="color:#111">)</span> <span style="color:#f92672">::</span> <span style="color:#00a8c8">Float</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">a</span> <span style="color:#111">}</span>
</span></span></code></pre></div><p>where the <code>~!!~</code> operator is analogous to the indexing operator on lists, <code>!! : [a] -&gt; Int -&gt; a</code>. This type is indeed an applicative functor (in fact, it is a specialization of the <code>Reader</code> monad):</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Functor</span> <span style="color:#00a8c8">CVector</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">fmap</span> <span style="color:#111">f</span> <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">CVector</span> <span style="color:#111">{</span> <span style="color:#111">(</span><span style="color:#f92672">~!!~</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">f</span> <span style="color:#f92672">.</span> <span style="color:#111">(</span><span style="color:#111">x</span> <span style="color:#f92672">~!!~</span><span style="color:#111">)</span> <span style="color:#111">}</span> 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#00a8c8">CVector</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pure</span> <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">CVector</span> <span style="color:#111">{</span> <span style="color:#111">(</span><span style="color:#f92672">~!!~</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">const</span> <span style="color:#111">x</span> <span style="color:#111">}</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pair</span> <span style="color:#111">x</span> <span style="color:#111">y</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">CVector</span> <span style="color:#111">{</span> <span style="color:#111">(</span><span style="color:#f92672">~!!~</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#75af00">\</span><span style="color:#111">t</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">(</span><span style="color:#111">x</span> <span style="color:#f92672">~!!~</span> <span style="color:#111">t</span><span style="color:#111">,</span> <span style="color:#111">y</span> <span style="color:#f92672">~!!~</span> <span style="color:#111">t</span><span style="color:#111">)</span> <span style="color:#111">}</span>
</span></span></code></pre></div><p>Mathematically, we can think of <code>v : CVector a</code> as a function $v \in \mathbb{R} \to a$, and we will notate it as such (i.e $v(x)$). Then the operations defined here can be interpreted as</p>
$$\begin{align*}
    \mathrm{fmap} &: f, x(t) ~~\to~~ v(t) = f(x(t)) \\
    \mathrm{pure} &: x ~~\to~~ v(t) = x \\
    \mathrm{pair} &: x(t), ~y(t) ~~\to ~~v(t) = (v(t), y(t))
\end{align*}$$<p>We also need instances of <code>Counit</code> for this type. Here, we can draw some inspiration from the original Transformer, where these corresponded to sums over the components of vectors, or sums of the rows of a matrix. Analagous to a sum over a vector, we can consider the integral of a function over its domain - of course, this is not straightforward to define in code, but let&rsquo;s pretend we have a magical black box:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">integrate</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span><span style="color:#00a8c8">Float</span> <span style="color:#f92672">-&gt;</span> <span style="color:#00a8c8">Float</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#00a8c8">Float</span>
</span></span></code></pre></div><p>Using this we can define:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Counit</span> <span style="color:#00a8c8">CVector</span> <span style="color:#00a8c8">Float</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">f</span> <span style="color:#f92672">=</span> <span style="color:#111">integrate</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#f92672">~!!~</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Counit</span> <span style="color:#00a8c8">CVector</span> <span style="color:#111">(</span><span style="color:#00a8c8">CVector</span> <span style="color:#00a8c8">Float</span><span style="color:#111">)</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">f</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">CVector</span> <span style="color:#111">{</span> <span style="color:#111">(</span><span style="color:#f92672">~!!~</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#75af00">\</span><span style="color:#111">y</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">integrate</span> <span style="color:#111">(</span><span style="color:#75af00">\</span><span style="color:#111">x</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#f92672">~!!~</span> <span style="color:#111">x</span> <span style="color:#f92672">~!!~</span> <span style="color:#111">y</span><span style="color:#111">)</span> <span style="color:#111">}</span>
</span></span></code></pre></div><p>Note here that our equivalent of a matrix, <code>v : CVector (CVector a)</code> is equivalent to a function with type $v : \mathbb{R} \to \mathbb{R} \to a$. By currying, this is the same as a two-argument function $v : \mathbb{R}^2 \to a$, and so we will notate it as $v(x, y)$. We can again interpret these operations mathematically, as:</p>
$$\begin{align*}
    \mathrm{counit_{a}} &: x(t) ~~\to~~ \int_{-\infty}^\infty x(t) ~\mathrm{dt} \\
    \mathrm{counit_{\mathbb{R} \to a}} &: x(t_1, t_2) ~~\to~~ v(t_2) = \int_{-\infty}^\infty x(t_1, t_2) ~\mathrm{dt_2}
\end{align*}$$<p>This is actually all we need to translate the whole Transformer into <code>CVector</code>s! Working through the code, we can have a look at what the building blocks operations become, mathematically:</p>
$$\begin{align*}
    \mathrm{dot} &: x(t), ~y(t) ~~\to~~ \int_{-\infty}^\infty x(t)y(t) ~\mathrm{dt} \\
    \mathrm{mulMV} &: m(t_1, t_2), ~v(t_2) ~~\to~~ u(t_1) = \int_{-\infty}^\infty m(t_1, t_2)v(t_2)~\mathrm{dt_2} \\
    \mathrm{mulMM} &: m_1(t_1, t_2), ~m_2(t_2, t_3) ~~\to~~ m_3(t_1, t_3) = \int_{-\infty}^\infty m_1(t_1, t_2)m_2(t_2, t_3)~\mathrm{dt_2}
\end{align*}$$<p>It is pleasing to see that dot products over vectors translate directly into the $L^2$ dot product on functions, and that the multiplication operations generalize matrix multiplication exactly as one would expect! (I&rsquo;ve skipped the transposed versions here because they are symmetric) Given $Q, K, V, W_1, W_2 \in \mathbb{R}^2 \to \mathbb{R}$, and $b_1, b_2 \in \mathbb{R} \to \mathbb{R}$, the MLP operation becomes</p>
$$\begin{align*}
    \mathrm{MLP} &: x(t_1, t_2) ~~\to~~ v(t_1, t_2) = \\
    &\int_{-\infty}^\infty\sigma\left(\int_{-\infty}^{\infty} x(t_1, t_3)W_1(t_3, t_4) ~\mathrm{dt_3} ~+~ b_1(t_4)\right)W_2(t_4, t_2) ~\mathrm{dt_4} + b_2(t_2)
\end{align*}$$<p>where $\sigma \in \mathbb{R} \to \mathbb{R}$ is some arbitrary activation function. If we take the obvious continuous generalization of the scaled-softmax operator to be given by</p>
$$ \rho : x(t) ~~\to~~ v(t) = \frac{e^{x(t)}}{\int_{-\infty}^\infty e^{x(t)} ~\mathrm{dt}}$$<p>then we can write the self-attention operation as:</p>
$$ \begin{align*}
    \mathrm{SelfAtt} : ~~&x(t_1, t_2) ~~\to~~ v(t_1, t_2) = \\
    &\int_{\mathbb{R}^2}\frac{e^{\int_{\mathbb{R}^3} x(t_1, t_3)Q(t_3, t_4)K(t_4, t_5)x(t_5, t_6) ~\mathrm{dt_3}\mathrm{dt_4}\mathrm{dt_5}}}{\int_{-\infty}^\infty e^{\int_{\mathbb{R}^3} x(t_1, t_3)Q(t_3, t_4)K(t_4, t_5)x(t_5, t_6) ~\mathrm{dt_3}\mathrm{dt_4}\mathrm{dt_5}}~\mathrm{dt_1}} x(t_6, t_7)V(t_7, t_2)~\mathrm{dt_6}\mathrm{dt_7}
\end{align*}$$<p>This is pretty gnarly! Obviously, there are very few functions where you could expect this to be exactly solvable, and really I&rsquo;m only writing it down here to show that it does in fact exist.</p>
<p>To regroup, let&rsquo;s just remind ourselves what we just derived: we replaced <code>Vector</code>s in the original Transformer with <code>CVector</code>s and so now we have a model that instead of mapping matrices to matrices, maps two-argument functions to two-argument functions! In the usual interpretation of the Transformer as it is applied to natural language processing, we consider one dimension of the matrix to be the &lsquo;sequence&rsquo; dimension (that is, it represents your position in the text), and the other to be the &lsquo;feature&rsquo; dimension (that is, it represents something about the meaning of the words at each position). So in our model, we can think perhaps that we have a continuum of text positions, and a continuum of features at each position, rather than finitely many of each.</p>
<p>So how can we make this idea practical? We need a way to represent functions and integration efficiently, and hence in a finite-dimensional way. This could be done with a table of values for each function and numerical integration, but it&rsquo;s both more efficient and more interesting to choose a different method. Since any function can be approximated as a polynomial, and it is easy to integrate polynomials, we can choose a set of polynomials that is closed under addition as our finite-dimensional representation. In particular, we make the following (arbitrary) choice, representing functions as 1D or 2D Chebyshev series:</p>
$$ f(x) = \sum_{i = 1}^N f_i T_i(x) ~~~~~f(x, y) = \sum_{i = 1}^N \sum_{j = 1}^N f_{ij}T_i(x)T_j(y)$$<p>where $T_n(x)$ represents the $n$-th Chebyshev polynomial of the first kind. Moreover, rather than considering domain of our functions to be the whole real line, we will just consider the range $[-1, 1]$. This choice of polynomials has the advantage that it is more numerically stable when interpolating data points than the standard monomial $a + bx + cx^2 + \cdots$ basis.</p>
<p>For $n, m, |n - m| \geq 1$ (and the other cases follow similarly), we can use a known result about Chebyshev polynmomials, that</p>
$$ \int_{-1}^1 T_n(x)T_m(x)~\mathrm{dx} = \frac{(1 + (-1)^{n + m})(1 - n^2 - m^2)}{(1 - (n + m)^2)(1 - (m - n)^2)} = W_{n, m}$$<p>which we define to be the components of the <em>weight matrix</em> $W_{n, m}$. Suppose then that we have two functions $f(x)$ and $g(x)$ represented as series with coefficients $f_i$ and $g_i$, then we can write their dot product defined above as</p>
$$ \begin{align*}
    \mathrm{dot}(f, g) &= \int_{-1}^{-1} f(x)g(x) ~\mathrm{dx} = \int_{-1}^1 \sum_{i = 0}^N\sum_{j = 0}^N f_i g_j T_i(x)T_j(x)~\mathrm{dx} \\
    &= \sum_{i = 0}^N\sum_{j = 0}^N f_i W_{ij} g_i = f_*^TWg_*
\end{align*}$$<p>if $f_*$ and $g_*$ are vectors representing the coefficients of the series. So we can see that a dot product of functions has become simply a dot product of vectors, albeit with respect to a different bilinear form than the usual dot product!</p>
<p>Indeed, this is also true for the (abstract) matrix-vector and matrix-matrix multiplication operations defined above. In the same way as above, let us denote $m_*$ as the matrix of coefficients $m_{ij}$ corresponding to a two-argument function $m(x, y)$. We have that:</p>
$$\begin{align*}
    \mathrm{mulMV} &: m_*, ~v_* ~~\to~~ u_* = m_* W v_* \\
    \mathrm{mulMM} &: a_*, ~b_* ~~\to~~ c_* = a_* W b_*
\end{align*}$$<p>This is almost all the parts we need to build a Transformer. The only thing that is left is activation function for the MLP and the softmax operation. While in the applicative-based code above, these were specified as element-wise and &lsquo;row&rsquo;-wise operations, respectively, in practice they could be almost anything.</p>
<p>For the activation function, we chose to keep very close to the original definition - you can approximately apply an elementwise operation to a function represented as a Chebyshev series by first evaluating the polynomial on a grid of points, applying the operation to each of those points, and then interpolating a series from the new values. This is particularly efficient for Chebyshev polynomials, as transforming between the series and point-grid representations can be done using a variant of the fast Fourier transform called the discrete Chebyshev transform, see for instance <a href="https://www.boost.org/doc/libs/1_87_0/libs/math/doc/html/math_toolkit/sf_poly/chebyshev.html">here</a> for details. We used this technique to apply the ReLU activation function.</p>
<p>For the softmax, we chose a slightly less faithful implementation, by applying the softmax operation row-wise directly to the matrix of coefficients. This is much more efficient than trying to apply it to the function values themselves, and seems to work well in practice. We note that the original purpose of the softmax in the Transformer is to ensure that each row of the &lsquo;attention matrix&rsquo; $XQ(XK)^T$ has nicely bounded values, and in the continuous case this is also achieved by applying the softmax to a coefficient vector, since bounded coefficients imply a bounded value of the overall function in a given domain.</p>
<p>At this point it is worth noting that this model is very similar to those constructed in the literature of neural operators <a href="https://arxiv.org/abs/2108.08481">[arXiv:2108.08481]</a> <a href="https://arxiv.org/abs/2003.03485">[arXiv:2003.03485]</a>. In particular a model called the Fourier neural operator <a href="https://arxiv.org/abs/2010.08895">[arXiv:2010.08895]</a> is a quite similar idea, replacing Chebyshev series with Fourier series. It is a good sanity check to see that our generic approach has yielded a model that has been previously considered and is regarded to be useful in practice, and it suggests that continuing this line of thought may lead to more useful models!</p>
<p>With these details worked out, it is possible to build this model explicitly in a machine learning framework such as PyTorch - we have a very basic implementation available on <a href="https://github.com/tlaakkonen/funcformer">GitHub</a>. As a very simple test, we can try the following task - given a function $f(x, y)$ we can define Poisson&rsquo;s equation:</p>
$$ \nabla^2 g(x, y) = \left(\frac{\partial g}{\partial x}\right)^2 + \left(\frac{\partial g}{\partial y}\right)^2 = f(x, y)$$<p>This is a partial differential equation that can be solved numerically via a variety of strategies (for instance, finite difference or collocation approaches). The right hand side $f(x, y)$ is conventionally known as the &lsquo;source term&rsquo;, and the solution $g(x, y)$ is sometimes called the &lsquo;potential&rsquo;. Since the process of solving this equation can be thought of as a map from source term to potential, then rather than solving this equation numerically, we will train a Funcformer model to do it for us! Note that this is not training a model to approximate the solution to a particular instance of Poisson&rsquo;s equation but a more general map from source terms to potential, as in the theory of operator learning <a href="https://arxiv.org/abs/1910.03193">[arXiv:1910.03193]</a>.</p>
<p>We trained the model on random smooth functions (i.e the highest-order Chebyshev coefficients were fixed to zero) with fixed boundary conditions of $f(x, \pm 1) = f(\pm 1, y) = 0$, and it appears to converge well. See below for an example solution, and see <a href="https://youtu.be/E2feLboNYwk">YouTube</a> for a video of how this example evolves throughout training.</p>
<figure class="align-center ">
    <img loading="lazy" src="images/before_example.png#center"
         alt="Before training: an example of Funcformer solving Poisson&rsquo;s equation." width="80%"/> <figcaption>
            <p>Before training: an example of Funcformer solving Poisson&rsquo;s equation.</p>
        </figcaption>
</figure>

<figure class="align-center ">
    <img loading="lazy" src="images/after_example.png#center"
         alt="After training: an example of Funcformer solving Poisson&rsquo;s equation." width="80%"/> <figcaption>
            <p>After training: an example of Funcformer solving Poisson&rsquo;s equation.</p>
        </figcaption>
</figure>

<h2 id="part-6-a-generalized-transformer-zoo">Part 6: A generalized Transformer zoo<a hidden class="anchor" aria-hidden="true" href="#part-6-a-generalized-transformer-zoo">#</a></h2>
<p>However, <code>CVector</code> is not the only alternative applicative functor we could use - let&rsquo;s run through some more that might be interesting! Before we start, it&rsquo;s worth pointing out that while we are using functional programming as a way to express these ideas, in practice these models can and should be implemented in an imperative language using a machine learning framework, as for any other model.</p>
<h4 id="expression-trees-and-dags">Expression trees and DAGs<a hidden class="anchor" aria-hidden="true" href="#expression-trees-and-dags">#</a></h4>
<p>Suppose we have a binary tree datatype defined like</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">data</span> <span style="color:#00a8c8">Tree</span> <span style="color:#111">l</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Node</span> <span style="color:#111">(</span><span style="color:#00a8c8">Tree</span> <span style="color:#111">l</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#00a8c8">Tree</span> <span style="color:#111">l</span><span style="color:#111">)</span> <span style="color:#f92672">|</span> <span style="color:#00a8c8">Leaf</span> <span style="color:#111">l</span>
</span></span></code></pre></div><p>then this is indeed an applicative functor:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Functor</span> <span style="color:#00a8c8">Tree</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">fmap</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#00a8c8">Node</span> <span style="color:#111">left</span> <span style="color:#111">right</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Node</span> <span style="color:#111">(</span><span style="color:#111">fmap</span> <span style="color:#111">f</span> <span style="color:#111">left</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">fmap</span> <span style="color:#111">f</span> <span style="color:#111">right</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">fmap</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#00a8c8">Leaf</span> <span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Leaf</span> <span style="color:#f92672">$</span> <span style="color:#111">f</span> <span style="color:#111">x</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">(</span><span style="color:#00a8c8">Tree</span> <span style="color:#111">op</span><span style="color:#111">)</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pure</span> <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Leaf</span> <span style="color:#111">x</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pair</span> <span style="color:#111">(</span><span style="color:#00a8c8">Node</span> <span style="color:#111">la</span> <span style="color:#111">ra</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#00a8c8">Node</span> <span style="color:#111">lb</span> <span style="color:#111">rb</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Node</span> <span style="color:#111">(</span><span style="color:#111">pair</span> <span style="color:#111">la</span> <span style="color:#111">lb</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">pair</span> <span style="color:#111">ra</span> <span style="color:#111">rb</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pair</span> <span style="color:#111">(</span><span style="color:#00a8c8">Node</span> <span style="color:#111">l</span> <span style="color:#111">r</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#00a8c8">Leaf</span> <span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Node</span> <span style="color:#111">(</span><span style="color:#111">fmap</span> <span style="color:#111">(,</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#111">l</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">fmap</span> <span style="color:#111">(,</span><span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#111">r</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pair</span> <span style="color:#111">(</span><span style="color:#00a8c8">Leaf</span> <span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#00a8c8">Node</span> <span style="color:#111">l</span> <span style="color:#111">r</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Node</span> <span style="color:#111">(</span><span style="color:#111">fmap</span> <span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">,)</span> <span style="color:#111">l</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">fmap</span> <span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">,)</span> <span style="color:#111">r</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pair</span> <span style="color:#111">(</span><span style="color:#00a8c8">Leaf</span> <span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#00a8c8">Leaf</span> <span style="color:#111">y</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Leaf</span> <span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">y</span><span style="color:#111">)</span>
</span></span></code></pre></div><p>We can think of the pair operation here as mapping two trees to their common refinement (i.e the smallest tree containing them both) by expanding leaves to subtrees where necessary, and then zipping the two trees together. Given any method of combining two leaves (for example, addition), we can define a counit for trees by combining leaves from the bottom-up:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span> <span style="color:#f92672">=&gt;</span> <span style="color:#00a8c8">Counit</span> <span style="color:#00a8c8">Tree</span> <span style="color:#111">a</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Node</span> <span style="color:#111">l</span> <span style="color:#111">r</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">counit</span> <span style="color:#111">l</span> <span style="color:#f92672">~+~</span> <span style="color:#111">counit</span> <span style="color:#111">r</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Leaf</span> <span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">x</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#111">(</span><span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#00a8c8">Counit</span> <span style="color:#00a8c8">Tree</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Node</span> <span style="color:#111">l</span> <span style="color:#111">r</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">uncurry</span> <span style="color:#111">(</span><span style="color:#f92672">~+~</span><span style="color:#111">)</span> <span style="color:#f92672">&lt;$&gt;</span> <span style="color:#111">pair</span> <span style="color:#111">(</span><span style="color:#111">counit</span> <span style="color:#111">l</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">counit</span> <span style="color:#111">r</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Leaf</span> <span style="color:#111">x</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">x</span>
</span></span></code></pre></div><p>We have previously tried to implement this in practice, but as you would expect it is very hard to do efficiently and especially in a GPU-accelerated way!</p>
<p>It is important to note that with this definition, all the structure of the trees has to be present in the input data, in some form - the generalized Transformer model cannot be used to, for example, infer a tree structure from data (at least not directly), because the output tree will always be the common refinement of the inputs - what the model is learning to modify is the values of the leaves.</p>
<p>There are two obvious extensions to this: general expression trees, where the operations used to combine each node may be stored in the node itself, and directed-acylic graphs, where the node combination procedes from sources to sinks. Various applications of this come to mind, for example, code synthesis and comprehension, or structured data retrieval.</p>
<h4 id="probability-distributions">Probability distributions<a hidden class="anchor" aria-hidden="true" href="#probability-distributions">#</a></h4>
<p>It is well known that you can form a monad from probability distributions (indeed, finite discrete distributions are essentially a variant of the list monad discussed earlier), and since all monads are applicative functors, this is sufficient for our purposes. We can write</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">data</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#111">[(</span><span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Float</span><span style="color:#111">)]</span>
</span></span></code></pre></div><p>to represent a finite discrete distribution, and we assume that it is constrained so that the probabilities can only take positive values, and sum to one. This is indeed a functor as expected:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Functor</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">fmap</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#00a8c8">Distribution</span> <span style="color:#111">dist</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#f92672">$</span> <span style="color:#111">map</span> <span style="color:#111">(</span><span style="color:#75af00">\</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">p</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">p</span><span style="color:#111">))</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pure</span> <span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#111">[(</span><span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#ae81ff">1.0</span><span style="color:#111">)]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">pair</span> <span style="color:#111">(</span><span style="color:#00a8c8">Distribution</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#00a8c8">Distribution</span> <span style="color:#111">b</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> 
</span></span><span style="display:flex;"><span>        <span style="color:#00a8c8">Distribution</span> <span style="color:#f92672">$</span> <span style="color:#111">zipWith</span> <span style="color:#111">(</span><span style="color:#75af00">\</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">px</span><span style="color:#111">)</span> <span style="color:#111">(</span><span style="color:#111">y</span><span style="color:#111">,</span> <span style="color:#111">py</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">((</span><span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">y</span><span style="color:#111">),</span> <span style="color:#111">px</span> <span style="color:#f92672">*</span> <span style="color:#111">py</span><span style="color:#111">))</span> <span style="color:#111">a</span> <span style="color:#111">b</span>
</span></span></code></pre></div><p>This would be very inefficient, and in practice, you should perform some kind step to combine equal outcomes in the distribution (but this is not permitted by the type signature of <code>Applicative</code> since it would require an equality typeclass constraint or similar). Indeed, this restriction is only due to the confines of expressing these operations in Haskell (where all functors must be endofunctors on $\mathrm{Hask}$), certainly continuous probability distributions also form a monad, and thus an applicative functor. For instance, if $X \sim D$ is a random variable, then the random variable $f(X) \sim f(D)$ should be well-defined if the codomain of $f$ is measurable. We would like to write this</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">data</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#111">{</span> <span style="color:#111">pdf</span> <span style="color:#f92672">::</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#00a8c8">Float</span> <span style="color:#111">}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Functor</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">fmap</span> <span style="color:#111">f</span> <span style="color:#111">dist</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#111">{</span> <span style="color:#111">pdf</span> <span style="color:#f92672">=</span> <span style="color:#f92672">...</span> <span style="color:#111">}</span>
</span></span></code></pre></div><p>but it is not possible to implement <code>Functor</code> here in a sensible way. This is possible with more advanced types, see for instance the <a href="https://hackage.haskell.org/package/monad-bayes"><code>monad-bayes</code> package</a>. <code>Counit</code> could be defined in many ways, but taking the expectation value of the distribution would appear to be a somewhat canonical choice:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Counit</span> <span style="color:#00a8c8">Distribution</span> <span style="color:#00a8c8">Float</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Distribution</span> <span style="color:#111">dist</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">sum</span> <span style="color:#f92672">$</span> <span style="color:#111">map</span> <span style="color:#111">(</span><span style="color:#111">uncurry</span> <span style="color:#111">(</span><span style="color:#f92672">*</span><span style="color:#111">))</span> <span style="color:#111">dist</span>
</span></span></code></pre></div><p>To make this practical, we could imagine parameterizing the space of all probability distributions either with finite discrete distributions as we defined above, or by some finite-dimensional representation such as a mixture of Gaussians. Furthermore, probability distributions over probability distributions (in the sense of <code>Distribution (Distribution Float)</code>) could be modeled using Gaussian processes or similar. The natural use-case would seem to be something like Bayesian inference or regression problems with uncertainties.</p>
<p>Finally, we can mention briefly that a generalization of <code>Distribution</code> to</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">data</span> <span style="color:#00a8c8">Quantum</span> <span style="color:#111">a</span> <span style="color:#f92672">=</span> <span style="color:#00a8c8">Quantum</span> <span style="color:#111">[(</span><span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Complex</span> <span style="color:#00a8c8">Float</span><span style="color:#111">)]</span>
</span></span></code></pre></div><p>permits the expression of quantum machine learning models in this framework, as they can be viewed as a kind of generalized probabilistic theory with complex-valued probabilities called amplitudes. <code>Functor</code> and <code>Applicative</code> would be defined exactly as before, but the counit is changed to be the expected value of the distribution given by Born&rsquo;s rule (that is, each probability is the squared magnitude of the corresponding amplitude):</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#00a8c8">instance</span> <span style="color:#00a8c8">Counit</span> <span style="color:#00a8c8">Quantum</span> <span style="color:#00a8c8">Float</span> <span style="color:#00a8c8">where</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">counit</span> <span style="color:#111">(</span><span style="color:#00a8c8">Quantum</span> <span style="color:#111">dist</span><span style="color:#111">)</span> <span style="color:#f92672">=</span> <span style="color:#111">sum</span> <span style="color:#f92672">$</span> <span style="color:#111">map</span> <span style="color:#111">(</span><span style="color:#75af00">\</span><span style="color:#111">(</span><span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">x</span> <span style="color:#f92672">*</span> <span style="color:#111">(</span><span style="color:#111">magnitude</span> <span style="color:#111">a</span><span style="color:#111">)</span><span style="color:#f92672">^</span><span style="color:#ae81ff">2</span><span style="color:#111">)</span> <span style="color:#111">dist</span>
</span></span></code></pre></div><p>Note that the generalized Transformer models defined in this way probably <em>cannot</em> be implemented efficiently on quantum computers.</p>
<h4 id="cross-modal-models">Cross-modal models<a hidden class="anchor" aria-hidden="true" href="#cross-modal-models">#</a></h4>
<p>Our applicative definition of attention is given by</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">attention</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">g</span><span style="color:#111">,</span> <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">attention</span> <span style="color:#111">softmax</span> <span style="color:#111">queries</span> <span style="color:#111">keys</span> <span style="color:#111">values</span> <span style="color:#f92672">=</span> <span style="color:#111">attMatrix</span> <span style="color:#111">`</span><span style="color:#111">mulMM</span><span style="color:#111">`</span> <span style="color:#111">values</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">where</span> <span style="color:#111">attMatrix</span> <span style="color:#f92672">=</span> <span style="color:#111">fmap</span> <span style="color:#111">softmax</span> <span style="color:#111">(</span><span style="color:#111">queries</span> <span style="color:#111">`</span><span style="color:#111">mulMMT</span><span style="color:#111">`</span> <span style="color:#111">keys</span><span style="color:#111">)</span>
</span></span></code></pre></div><p>which does not constrain the two &lsquo;dimensions&rsquo; of the input (<code>f</code> and <code>g</code>) beyond that they must be applicative functors - thus they don&rsquo;t have to be the same! So our model easily generalizes then to various combinations of the functors we have already defined - for instance, we could consider inputs that are typed like vectors of functions, trees of probability distributions, and so on.</p>
<p>However, we can go further - note that we can actually make the type-signature of <code>attention</code> significantly less restrictive without changing its definition:</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-haskell" data-lang="haskell"><span style="display:flex;"><span><span style="color:#75af00">attention</span> <span style="color:#f92672">::</span> <span style="color:#111">(</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Applicative</span> <span style="color:#111">f</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">g</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">h</span><span style="color:#111">,</span> <span style="color:#00a8c8">Applicative</span> <span style="color:#111">i</span><span style="color:#111">,</span> 
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">Ring</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">h</span> <span style="color:#111">a</span><span style="color:#111">,</span> <span style="color:#00a8c8">Counit</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#111">)</span> <span style="color:#f92672">=&gt;</span> <span style="color:#111">(</span><span style="color:#111">f</span> <span style="color:#111">a</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">h</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">i</span> <span style="color:#111">(</span><span style="color:#111">h</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">f</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span> <span style="color:#f92672">-&gt;</span> <span style="color:#111">i</span> <span style="color:#111">(</span><span style="color:#111">g</span> <span style="color:#111">a</span><span style="color:#111">)</span>
</span></span><span style="display:flex;"><span><span style="color:#75af00">attention</span> <span style="color:#111">softmax</span> <span style="color:#111">queries</span> <span style="color:#111">keys</span> <span style="color:#111">values</span> <span style="color:#f92672">=</span> <span style="color:#111">attMatrix</span> <span style="color:#111">`</span><span style="color:#111">mulMM</span><span style="color:#111">`</span> <span style="color:#111">values</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">where</span> <span style="color:#111">attMatrix</span> <span style="color:#f92672">=</span> <span style="color:#111">fmap</span> <span style="color:#111">softmax</span> <span style="color:#111">(</span><span style="color:#111">queries</span> <span style="color:#111">`</span><span style="color:#111">mulMMT</span><span style="color:#111">`</span> <span style="color:#111">keys</span><span style="color:#111">)</span>
</span></span></code></pre></div><p>In this definition the <code>queries</code> and <code>keys</code> may come from an entirely different source than the <code>values</code>, and have a completely different type! This is similar in spirit to the cross-attention operation used in encoder-decoder architectures, where the keys and values may come from text in one language (for example) and the queries come from a different stream that represents text in another language. This is also used for multi-modal models that incorporate both text and image inputs. We can imagine building generalized multi-modal Transformers that can incoporate not just different streams of similarly typed data, but also distinctly typed data, for instance transforming text to trees (e.g parsing) or images to functions (e.g resolution-independent image upscaling).</p>
<h2 id="part-7-conclusion">Part 7: Conclusion<a hidden class="anchor" aria-hidden="true" href="#part-7-conclusion">#</a></h2>
<p>To summarize, we have observed that the Transformer, which is a model that maps sequences of vectors to sequences of vectors, can be generalized to map (almost) arbitrary applicative functors to applicative functors. It can also be described in a purely diagrammatic way based on tube diagrams. Then, we showed how a model based on the <code>CVector</code> applicative functor (that is related to the <code>Reader</code> monad) can be implemented in practice, and yields a model similar to those considered in the neural operator literature. Finally, we suggested some other functors that may yield interesting models, and considered how multi-modal models come about as a natural consequence of our framework.</p>
<p>Regarding future work: although in this post we&rsquo;ve talked mainly about transformers, all the pieces are there to build many other architectures &ndash; for instance, recurrent neural networks. Additionally, while interesting in theory, serious engineering effort (i.e custom GPU kernels) would be required to develop any of these models beyond the toy-scale, because the foundational building block of performant machine learning on modern GPUs - linear algebra, and especially matrix multiplication - is what we are generalizing! Unfortunately, until that work is done, it isn&rsquo;t obvious that these models perform better in practice than the normal Transformer. However, if a set of efficient kernels were developed for each applicative functor of interest (say trees, vectors, and functions), then you can imagine being able to plug them together to generate efficient models for any combination of types.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>In discussions we called them &ldquo;black-boxes&rdquo; among ourselves, but we coloured them red because we worked on blackboards, and so could not have black. So now red is the new black. This continues an Oxonian string-diagram tradition of picking bad colour conventions on the basis of what writing instruments were readily available.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://localhost:1313/tags/functional-programming/">Functional Programming</a></li>
      <li><a href="http://localhost:1313/tags/machine-learning/">Machine Learning</a></li>
    </ul>
  </footer><div id="gh-comments">
    <br/><br/>
    <h2 id="gh-comments-title">Comments</h2>
    <div id="gh-comments-list"></div>
    <a href="javascript:void(0)" id="gh-load-comments" class="btn" style="display:none">Load more comments</a>
</div>

<script type="text/javascript" src="http://localhost:1313/js/github-comments.js"></script>
<script type="text/javascript">
    DoGithubComments(["tlaakkonen"],  1 );
</script>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
</body>

</html>
